{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN과 CNN을 활용한 텍스트 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저자의 텍스트 분류 코드: [https://github.com/kh-kim/simple-ntc](https://github.com/kh-kim/simple-ntc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN image](https://pat-coady.github.io/rnn/assets/rnn_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RNN 텍스트 분류기 구조 (책의 250p에도 RNN 구조 그림이 있습니다.)\n",
    "* RNN을 사용한 텍스트 분류:\n",
    " * RNN은 문장의 단어를 순차적으로 입력받으며 학습한다.\n",
    " * RNN의 마지막 hidden state h_t을 입력 문장의 representation으로 봄\n",
    " * 최종적으로 softmax를 사용해 특정 class로 예상하는 확률들을 계산한다.\n",
    "\n",
    "실제 저자의 구현은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load simple-ntc/simple_ntc/rnn.py\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 word_vec_dim, \n",
    "                 hidden_size, \n",
    "                 n_classes,\n",
    "                 n_layers=4, \n",
    "                 dropout_p=.3\n",
    "                 ):\n",
    "        \n",
    "        # RNN 파라미터\n",
    "        self.input_size = input_size  # vocabulary_size\n",
    "        self.word_vec_dim = word_vec_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN 레이어 구성\n",
    "        self.emb = nn.Embedding(input_size, word_vec_dim)\n",
    "        self.rnn = nn.LSTM(input_size=word_vec_dim,\n",
    "                           hidden_size=hidden_size,\n",
    "                           num_layers=n_layers,\n",
    "                           dropout=dropout_p,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True\n",
    "                           )\n",
    "        self.generator = nn.Linear(hidden_size * 2, n_classes)\n",
    "        \n",
    "        # We use LogSoftmax + NLLLoss instead of Softmax + CrossEntropy\n",
    "        # -> https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss\n",
    "        # -> 위글을 참고하면 Logsoftmax + NLLLoss = Softmax + CrossEntropy입니다.\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        # |x| = (batch_size, length, word_vec_dim)\n",
    "        #  _  = LSTM의 cell state\n",
    "        x, _ = self.rnn(x)\n",
    "        # |x| = (batch_size, length, hidden_size * 2)\n",
    "        y = self.activation(self.generator(x[:, -1]))\n",
    "        # |y| = (batch_size, n_classes)\n",
    "\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer bi-LSTM with dropout?\n",
    "\n",
    "* Pytorch의 nn.lstm은 멀티 레이어, 양방향 레이어, dropout을 파라미터로 설정해줄 수 있습니다.\n",
    "* RNN 계열에서 dropout은 [Recurrent Neural Network Regularization](https://arxiv.org/abs/1409.2329) 논문에서 처음으로 잘 동작하도록 사용했다고 합니다. ([관련 블로그 글](http://sanghyukchun.github.io/89/))\n",
    "* 중요한 부분은 아래 option2 그림처럼 multi-layer에서 dropout이 사용되며, dropout은 recurrent connection이 아닌 부분에만 적용해야 하는 것이라고 합니다.\n",
    "\n",
    "* Reference: (https://discuss.pytorch.org/t/lstm-dropout-clarification-of-last-layer/5588)\n",
    "\n",
    "![multi-layer LSTM with dropout](https://discuss.pytorch.org/uploads/default/original/2X/6/62f94ceee433b693ef73be231f51ae4291e53880.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/JN72JHW.png)\n",
    "\n",
    "* CNN 텍스트 분류기 구조 ([Yoon Kim(2014)](http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf))\n",
    "\n",
    "* CNN을 사용한 텍스트 분류:\n",
    " * 문장의 단어들을 window 단위로 convolution 하여 feature를 추출한다.\n",
    " \n",
    "저자의 구현은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load simple-ntc/simple_ntc/cnn.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 word_vec_dim,\n",
    "                 n_classes,\n",
    "                 use_batch_norm=False,\n",
    "                 dropout_p=.5,\n",
    "                 window_sizes=[3, 4, 5],\n",
    "                 n_filters=[100, 100, 100]\n",
    "                 ):\n",
    "        # CNN 파라미터\n",
    "        self.input_size = input_size  # vocabulary size\n",
    "        self.word_vec_dim = word_vec_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "        # window_size means that how many words a pattern covers.\n",
    "        self.window_sizes = window_sizes\n",
    "        # n_filters means that how many patterns to cover.\n",
    "        self.n_filters = n_filters\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN 텍스트 분류기 레이어 구조\n",
    "        self.emb = nn.Embedding(input_size, word_vec_dim)\n",
    "        # Since number of convolution layers would be vary depend on len(window_sizes),\n",
    "        # we use 'setattr' and 'getattr' methods to add layers to nn.Module object.\n",
    "        # -> custom layer을 추가(setattr)하고, 불러와 사용하는 것(getattr)\n",
    "        for window_size, n_filter in zip(window_sizes, n_filters):\n",
    "            cnn = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=n_filter,\n",
    "                            kernel_size=(window_size, word_vec_dim)\n",
    "                            )\n",
    "            setattr(self, 'cnn-%d-%d' % (window_size, n_filter), cnn)\n",
    "\n",
    "            if use_batch_norm:\n",
    "                bn = nn.BatchNorm2d(n_filter)\n",
    "                setattr(self, 'bn-%d-%d' % (window_size, n_filter), bn)\n",
    "        # Because below layers are just operations, \n",
    "        # (it does not have learnable parameters)\n",
    "        # we just declare once.\n",
    "        \n",
    "        if not use_batch_norm:\n",
    "            self.dropout = nn.Dropout(dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "        # An input of generator layer is max values from each filter.\n",
    "        self.generator = nn.Linear(sum(n_filters), n_classes)\n",
    "        # We use LogSoftmax + NLLLoss instead of Softmax + CrossEntropy\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        # |x| = (batch_size, length, word_vec_dim)\n",
    "        min_length = max(self.window_sizes)\n",
    "        if min_length > x.size(1):\n",
    "            # Because some input does not long enough for maximum length of window size,\n",
    "            # we add zero tensor for padding.\n",
    "            pad = x.new(x.size(0), min_length - x.size(1), self.word_vec_dim).zero_()\n",
    "            # |pad| = (batch_size, min_length - length, word_vec_dim)\n",
    "            x = torch.cat([x, pad], dim=1)\n",
    "            # |x| = (batch_size, min_length, word_vec_dim)\n",
    "\n",
    "        # In ordinary case of vision task, you may have 3 channels on tensor,\n",
    "        # but in this case, you would have just 1 channel,\n",
    "        # which is added by 'unsqueeze' method in below:\n",
    "        x = x.unsqueeze(1)\n",
    "        # |x| = (batch_size, 1, length, word_vec_dim)\n",
    "\n",
    "        cnn_outs = []\n",
    "        for window_size, n_filter in zip(self.window_sizes, self.n_filters):\n",
    "            cnn = getattr(self, 'cnn-%d-%d' % (window_size, n_filter))\n",
    "            if self.use_batch_norm:\n",
    "                bn = getattr(self, 'bn-%d-%d' % (window_size, n_filter))\n",
    "                cnn_out = bn(self.relu(cnn(x)))\n",
    "            else:\n",
    "                cnn_out = self.dropout(self.relu(cnn(x)))\n",
    "            # |cnn_out| = (batch_size, n_filter, length - window_size + 1, 1)\n",
    "\n",
    "            # In case of max pooling, we does not know the pooling size,\n",
    "            # because it depends on the length of the sentence.\n",
    "            # Therefore, we use instant function using 'nn.functional' package.\n",
    "            # This is the beauty of PyTorch. :)\n",
    "            cnn_out = nn.functional.max_pool1d(input=cnn_out.squeeze(-1),\n",
    "                                               kernel_size=cnn_out.size(-2)\n",
    "                                               ).squeeze(-1)\n",
    "            # |cnn_out| = (batch_size, n_filter)\n",
    "            cnn_outs += [cnn_out]\n",
    "        # Merge output tensors from each convolution layer.\n",
    "        cnn_outs = torch.cat(cnn_outs, dim=-1)\n",
    "        # |cnn_outs| = (batch_size, sum(n_filters))\n",
    "        y = self.activation(self.generator(cnn_outs))\n",
    "        # |y| = (batch_size, n_classes)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습/테스트 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저자의 경우 클리앙 사이트의 글을 크롤링한 후, 게시글의 카테고리 분류를 수행했습니다.\n",
    "\n",
    "그러나 저자가 데이터를 제공하고 있지 않고, [클리앙 크롤링 코드](https://github.com/kh-kim/clien_crawler)는 제대로 동작하지 않는 것 같아\n",
    "저는 [AI hub의 한국어 대화 데이터](http://www.aihub.or.kr/content/553)를 사용하겠습니다.\n",
    "\n",
    "![한국어 대화 데이터 구조](http://www.aihub.or.kr/sites/default/files/%E1%84%83%E1%85%A2%E1%84%92%E1%85%AA%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5_%E1%84%80%E1%85%AE%E1%84%89%E1%85%A5%E1%86%BC%E1%84%83%E1%85%A9.JPG)\n",
    "\n",
    "해당 데이터는 AI hub를 통해 직접 다운 받으셔야 합니다.\n",
    "학습을 위한 데이터는 제가 공유드린 parsing.py 파일을 사용해 간단하게 생성할 수 있습니다.\n",
    "\n",
    "이번 텍스트 분류 실습에서는 대화의 카테고리를 분류해보는 것을 해보도록 하겠습니다.\n",
    "\n",
    "데이터는 대략 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "펜션/캠핑장\t재료는 직접 사 와야 하나요?\n",
      "상가\t건물이 몇 년도에 지어졌어요?\n",
      "모텔/여관\t제일 작은방은 없나요?\n",
      "pc방\t네 화장실 다녀온 후 라면 가지러 오겠습니다\n",
      "화장품\t여기 이 제품 새 제품 있나요?\n",
      "미용실\t남자만 머리할 수 있어요?\n",
      "옷수선집\t영업시간 좀 문의드려요\n",
      "카페\t몇 시에서 몇 시까지 영업하세요?\n",
      "신발\t요 신발은 몇 문이에요?\n",
      "반찬가게\t혹시 현금영수증 돼요?\n"
     ]
    }
   ],
   "source": [
    "!head -10 data/dialog/category_corpus.txt.shuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저자 코드의 구조를 살펴보면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 72\n",
      "-rwxr-xr-x  1 DongGyun  staff  8624  9 23 19:52 \u001b[31mREADME.md\u001b[m\u001b[m*\n",
      "drwxr-xr-x  4 DongGyun  staff   128 10  1 19:22 \u001b[34m__pycache__\u001b[m\u001b[m/\n",
      "-rwxr-xr-x  1 DongGyun  staff  4609  9 23 19:52 \u001b[31mclassify.py\u001b[m\u001b[m*\n",
      "-rwxr-xr-x  1 DongGyun  staff  3396  9 23 19:52 \u001b[31mdata_loader.py\u001b[m\u001b[m*\n",
      "-rwxr-xr-x  1 DongGyun  staff  1201  9 23 19:52 \u001b[31mget_confusion_matrix.py\u001b[m\u001b[m*\n",
      "drwxr-xr-x  8 DongGyun  staff   256 10  2 22:24 \u001b[34msimple_ntc\u001b[m\u001b[m/\n",
      "-rwxr-xr-x  1 DongGyun  staff  4045  9 23 19:52 \u001b[31mtrain.py\u001b[m\u001b[m*\n",
      "-rwxr-xr-x  1 DongGyun  staff   725  9 23 19:52 \u001b[31mutils.py\u001b[m\u001b[m*\n"
     ]
    }
   ],
   "source": [
    "%ll simple-ntc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train.py: 학습 할때 실행하게 될 파이썬 코드입니다. 학습의 파라미터 설정에 대한 정보를 넘겨줄 수 있고, 학습 결과를 어떻게 저장할지 등을 설정합니다.\n",
    "* classify.py:\n",
    "* data_loader.py:\n",
    "* utils.py:\n",
    "* get_confusion_matrix.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\n",
      "-rwxr-xr-x  1 DongGyun  staff     0  9 23 19:52 \u001b[31m__init__.py\u001b[m\u001b[m*\n",
      "drwxr-xr-x  6 DongGyun  staff   192 10  1 19:20 \u001b[34m__pycache__\u001b[m\u001b[m/\n",
      "-rwxr-xr-x  1 DongGyun  staff  4212  9 23 19:52 \u001b[31mcnn.py\u001b[m\u001b[m*\n",
      "-rwxr-xr-x  1 DongGyun  staff  1449  9 23 19:52 \u001b[31mrnn.py\u001b[m\u001b[m*\n",
      "-rwxr-xr-x  1 DongGyun  staff  3771  9 23 19:52 \u001b[31mtrainer.py\u001b[m\u001b[m*\n"
     ]
    }
   ],
   "source": [
    "%ll simple-ntc/simple_ntc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* rnn.py & cnn.py: 앞서 설명드렸던 RNN, CNN 모델 파일입니다.\n",
    "* trainer.py: 저자는 pytorch 모델 학습의 코드를 더 간략하게 작성하기 위하여 ignite를 사용했습니다. 이 파일은 그 ignite 사용에 대한 부분이 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 186480\n",
      "-rw-r--r--  1 DongGyun  staff         0 10  3 16:29 Domain_corpus.txt\n",
      "-rw-r--r--  1 DongGyun  staff   5885165 10  3 16:29 Intent_corpus.txt\n",
      "-rw-r--r--  1 DongGyun  staff   2720816 10  3 16:29 category_corpus.txt\n",
      "-rw-r--r--  1 DongGyun  staff   2720816 10  3 16:29 category_corpus.txt.shuf\n",
      "-rw-r--r--  1 DongGyun  staff   2450240 10  3 16:29 category_corpus.txt.shuf.train\n",
      "-rw-r--r--  1 DongGyun  staff    270576 10  3 16:29 category_corpus.txt.shuf.valid\n",
      "-rw-------  1 DongGyun  staff  35637997  5  7 16:39 dialog.json\n",
      "-rw-------  1 DongGyun  staff  23974499  5  7 16:53 dialog.xml\n",
      "-rw-r--r--  1 DongGyun  staff   2720816 10  1 19:07 dialog_category.data\n",
      "-rw-r--r--  1 DongGyun  staff   2720816 10  1 19:16 raw_corpus.shuf.txt\n",
      "-rw-r--r--  1 DongGyun  staff   2459022 10  1 19:18 raw_corpus.train.txt\n",
      "-rw-r--r--  1 DongGyun  staff   2720816 10  1 19:13 raw_corpus.txt\n",
      "-rw-r--r--  1 DongGyun  staff    262388 10  1 19:17 raw_corpus.valid.txt\n",
      "-rw-------  1 DongGyun  staff   9036454  5  7 17:31 ᄃ��화데이터(최종)_05071727.zip\n"
     ]
    }
   ],
   "source": [
    "%ll data/dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# 콘솔에서 아래 명령어를 통해 학습을 수행합니다.\n",
    "\n",
    "\\# RNN\n",
    "python simple-ntc/train.py --model_fn ./models/model.pth --train ./data/dialog/category_corpus.txt.shuf.train --valid ./data/dialog/category_corpus.txt.shuf.valid --rnn --gpu_id -1\n",
    "\n",
    "\\# CNN\n",
    "python simple-ntc/train.py --model_fn ./models/model.pth --train ./data/dialog/category_corpus.txt.shuf.train --valid ./data/dialog/category_corpus.txt.shuf.valid --rnn --gpu_id -1\n",
    "\n",
    "\\# RNN&CNN ensemble\n",
    "python simple-ntc/train.py --model_fn ./models/model.pth --train ./data/dialog/category_corpus.txt.shuf.train --valid ./data/dialog/category_corpus.txt.shuf.valid --rnn -cnn --gpu_id -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "펜션/캠핑장 호텔 모텔/여관\t재료는 직접 사 와야 하나요?\n",
      "상가 주택 토지\t건물이 몇 년도에 지어졌어요?\n",
      "당구장 카페 모텔/여관\t제일 작은방은 없나요?\n",
      "pc방 일반홀서빙음식점 당구장\t네 화장실 다녀온 후 라면 가지러 오겠습니다\n",
      "화장품 의류 가방\t여기 이 제품 새 제품 있나요?\n",
      "미용실 약국 화장품\t남자만 머리할 수 있어요?\n",
      "세탁소 여권 옷수선집\t영업시간 좀 문의드려요\n",
      "제과점 카페 셀프서비스음식점\t몇 시에서 몇 시까지 영업하세요?\n",
      "신발 의류 가방\t요 신발은 몇 문이에요?\n",
      "셀프서비스음식점 일반홀서빙음식점 세탁소\t혹시 현금영수증 돼요?\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 ./data/dialog/category_corpus.txt.shuf.valid | awk -F'\\t' '{ print $2 }' | python simple-ntc/classify.py --model ./models/rnn_model.pth --gpu_id -1 --top_k 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "펜션/캠핑장 옷수선집 상가\t재료는 직접 사 와야 하나요?\n",
      "상가 주택 가방\t건물이 몇 년도에 지어졌어요?\n",
      "일반홀서빙음식점 반찬가게 카페\t제일 작은방은 없나요?\n",
      "pc방 일반홀서빙음식점 셀프서비스음식점\t네 화장실 다녀온 후 라면 가지러 오겠습니다\n",
      "화장품 신발 의류\t여기 이 제품 새 제품 있나요?\n",
      "미용실 일반홀서빙음식점 청과물\t남자만 머리할 수 있어요?\n",
      "옷수선집 셀프서비스음식점 일반홀서빙음식점\t영업시간 좀 문의드려요\n",
      "카페 일반홀서빙음식점 옷수선집\t몇 시에서 몇 시까지 영업하세요?\n",
      "신발 가방 의류\t요 신발은 몇 문이에요?\n",
      "일반홀서빙음식점 카페 셀프서비스음식점\t혹시 현금영수증 돼요?\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 ./data/dialog/category_corpus.txt.shuf.valid | awk -F'\\t' '{ print $2 }' | python simple-ntc/classify.py --model ./models/cnn_model.pth --gpu_id -1 --top_k 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
