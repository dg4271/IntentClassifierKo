{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# [ref]\n",
    "# https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "# https://github.com/jeradf/bookspace/blob/master/example/doc2vec_moviespace.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from pprint import pprint\n",
    "import _pickle as cPickle\n",
    "\n",
    "from gensim.models import Doc2Vec, Phrases\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.matutils import unitvec\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.parsing.preprocessing import STOPWORDS as stop_words\n",
    "letters = list('abcdefghijklmnopqrstuvwxyz')\n",
    "numbers = list('123456789')\n",
    "stop_words = stop_words.union(set(letters)).union(set(numbers))\n",
    "\n",
    "import logging\n",
    "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actors</th>\n",
       "      <th>awards</th>\n",
       "      <th>country</th>\n",
       "      <th>director</th>\n",
       "      <th>genres</th>\n",
       "      <th>first_year</th>\n",
       "      <th>last_year</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>language</th>\n",
       "      <th>metascore</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>rating</th>\n",
       "      <th>rev_text</th>\n",
       "      <th>type</th>\n",
       "      <th>votes</th>\n",
       "      <th>writer</th>\n",
       "      <th>writers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption (1994)</td>\n",
       "      <td>[Tim Robbins, Morgan Freeman, Bob Gunton, Will...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Stephen King, Frank Darabont]</td>\n",
       "      <td>[Crime, Drama]</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BODU4MjU4...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>Why do I want to write the 234th comment on Th...</td>\n",
       "      <td>movie</td>\n",
       "      <td>1684836.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Stephen King, Frank Darabont]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight (2008)</td>\n",
       "      <td>[Christian Bale, Heath Ledger, Aaron Eckhart, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Jonathan Nolan, Christopher Nolan]</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTMxNTMw...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>We've been subjected to enormous amounts of hy...</td>\n",
       "      <td>movie</td>\n",
       "      <td>1670736.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Jonathan Nolan, Christopher Nolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inception (2010)</td>\n",
       "      <td>[Leonardo DiCaprio, Joseph Gordon-Levitt, Elle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Christopher Nolan]</td>\n",
       "      <td>[Action, Adventure, Sci-Fi, Thriller]</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>tt1375666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMjAxMzY3...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>I'd like to keep my review rather to the point...</td>\n",
       "      <td>movie</td>\n",
       "      <td>1462859.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Christopher Nolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>[Brad Pitt, Edward Norton, Meat Loaf, Zach Gre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Chuck Palahniuk, Jim Uhls]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>tt0137523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BNGM2NjQx...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>\\nWhen I first saw the previews for this movie...</td>\n",
       "      <td>movie</td>\n",
       "      <td>1347001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Chuck Palahniuk, Jim Uhls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>[John Travolta, Uma Thurman, Samuel L. Jackson...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Quentin Tarantino, Roger Avary]</td>\n",
       "      <td>[Crime, Drama]</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994</td>\n",
       "      <td>tt0110912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTkxMTA5...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>One of the early scenes in \"Pulp Fiction\" feat...</td>\n",
       "      <td>movie</td>\n",
       "      <td>1324182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Quentin Tarantino, Roger Avary]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "0  The Shawshank Redemption (1994)   \n",
       "1           The Dark Knight (2008)   \n",
       "2                 Inception (2010)   \n",
       "3                Fight Club (1999)   \n",
       "4              Pulp Fiction (1994)   \n",
       "\n",
       "                                              actors awards country  \\\n",
       "0  [Tim Robbins, Morgan Freeman, Bob Gunton, Will...    NaN     NaN   \n",
       "1  [Christian Bale, Heath Ledger, Aaron Eckhart, ...    NaN     NaN   \n",
       "2  [Leonardo DiCaprio, Joseph Gordon-Levitt, Elle...    NaN     NaN   \n",
       "3  [Brad Pitt, Edward Norton, Meat Loaf, Zach Gre...    NaN     NaN   \n",
       "4  [John Travolta, Uma Thurman, Samuel L. Jackson...    NaN     NaN   \n",
       "\n",
       "                              director                                 genres  \\\n",
       "0       [Stephen King, Frank Darabont]                         [Crime, Drama]   \n",
       "1  [Jonathan Nolan, Christopher Nolan]       [Action, Crime, Drama, Thriller]   \n",
       "2                  [Christopher Nolan]  [Action, Adventure, Sci-Fi, Thriller]   \n",
       "3          [Chuck Palahniuk, Jim Uhls]                                [Drama]   \n",
       "4     [Quentin Tarantino, Roger Avary]                         [Crime, Drama]   \n",
       "\n",
       "   first_year  last_year    imdb_id language metascore  \\\n",
       "0        1994       1994  tt0111161      NaN       NaN   \n",
       "1        2008       2008  tt0468569      NaN       NaN   \n",
       "2        2010       2010  tt1375666      NaN       NaN   \n",
       "3        1999       1999  tt0137523      NaN       NaN   \n",
       "4        1994       1994  tt0110912      NaN       NaN   \n",
       "\n",
       "                                          poster_url  rating  \\\n",
       "0  http://ia.media-imdb.com/images/M/MV5BODU4MjU4...     9.3   \n",
       "1  http://ia.media-imdb.com/images/M/MV5BMTMxNTMw...     9.0   \n",
       "2  http://ia.media-imdb.com/images/M/MV5BMjAxMzY3...     8.8   \n",
       "3  http://ia.media-imdb.com/images/M/MV5BNGM2NjQx...     8.8   \n",
       "4  http://ia.media-imdb.com/images/M/MV5BMTkxMTA5...     8.9   \n",
       "\n",
       "                                            rev_text   type      votes writer  \\\n",
       "0  Why do I want to write the 234th comment on Th...  movie  1684836.0    NaN   \n",
       "1  We've been subjected to enormous amounts of hy...  movie  1670736.0    NaN   \n",
       "2  I'd like to keep my review rather to the point...  movie  1462859.0    NaN   \n",
       "3  \\nWhen I first saw the previews for this movie...  movie  1347001.0    NaN   \n",
       "4  One of the early scenes in \"Pulp Fiction\" feat...  movie  1324182.0    NaN   \n",
       "\n",
       "                               writers  \n",
       "0       [Stephen King, Frank Darabont]  \n",
       "1  [Jonathan Nolan, Christopher Nolan]  \n",
       "2                  [Christopher Nolan]  \n",
       "3          [Chuck Palahniuk, Jim Uhls]  \n",
       "4     [Quentin Tarantino, Roger Avary]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('top_5500_movies_and_shows.df')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "f_name_plot = open('name_plot.txt', 'r')\n",
    "#name_plot_dic = defaultdict(list)\n",
    "\n",
    "name_list = []\n",
    "plot_list = []\n",
    "\n",
    "name_plots = f_name_plot.readlines()\n",
    "for row in name_plots:\n",
    "    name_plot = row.split('\\t')\n",
    "    #name_plot_dic[name_plot[0]] = name_plot[1]\n",
    "    if(len(name_plot) == 2):\n",
    "        name_list.append(name_plot[0])\n",
    "        plot_list.append(name_plot[1])\n",
    "    \n",
    "f_name_plot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "RE_PUNCT = re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove all punctuation and make all lowercase \n",
    "    return RE_PUNCT.sub(\" \", text).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-15 12:58:00,277 : INFO : collecting all words and their counts\n",
      "2017-06-15 12:58:00,281 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-15 12:58:06,966 : INFO : collected 1529038 word types from a corpus of 4813925 words (unigram + bigrams) and 8472 sentences\n",
      "2017-06-15 12:58:06,966 : INFO : using 1529038 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "/home/hong/anaconda3/lib/python3.5/site-packages/gensim/models/phrases.py:274: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "def make_movie_doc(text, title, drop_stopwords=True):\n",
    "    \"\"\"Make documents into LabeledSentence objects for doc2vec training\"\"\"\n",
    "    doctag = '_'.join(preprocess(title))    \n",
    "    docwords = list(filter(lambda word: word not in stop_words,\n",
    "                      bigram[preprocess(text)]))\n",
    "    return LabeledSentence(docwords, [doctag])\n",
    "\n",
    "# Train bigrammer to detect two-word phrases, e.g., breaking_bad\n",
    "#bigram = Phrases(map(preprocess, df.rev_text.tolist())) \n",
    "bigram = Phrases(map(preprocess, plot_list)) \n",
    "\n",
    "#DOCS = [make_movie_doc(text, title) for text, title in\n",
    "#        zip(df.rev_text.tolist(), df.title.tolist())]\n",
    "DOCS = [make_movie_doc(text, title) for text, title in\n",
    "        zip(plot_list, name_list)]\n",
    "\n",
    "\n",
    "\n",
    "shuffle(DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-15 12:58:27,206 : INFO : collecting all words and their counts\n",
      "2017-06-15 12:58:27,207 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2017-06-15 12:58:27,696 : INFO : collected 92200 word types and 8470 unique tags from a corpus of 8472 examples and 2394249 words\n",
      "2017-06-15 12:58:27,697 : INFO : Loading a fresh vocabulary\n",
      "2017-06-15 12:58:28,295 : INFO : min_count=4 retains 48512 unique words (52% of original 92200, drops 43688)\n",
      "2017-06-15 12:58:28,295 : INFO : min_count=4 leaves 2327785 word corpus (97% of original 2394249, drops 66464)\n",
      "2017-06-15 12:58:28,397 : INFO : deleting the raw counts dictionary of 92200 items\n",
      "2017-06-15 12:58:28,400 : INFO : sample=0.0001 downsamples 513 most-common words\n",
      "2017-06-15 12:58:28,400 : INFO : downsampling leaves estimated 2044034 word corpus (87.8% of prior 2327785)\n",
      "2017-06-15 12:58:28,400 : INFO : estimated required memory for 48512 words and 100 dimensions: 68147600 bytes\n",
      "2017-06-15 12:58:28,539 : INFO : resetting layer weights\n",
      "2017-06-15 12:58:29,078 : INFO : training model with 8 workers on 48512 vocabulary and 100 features, using sg=1 hs=0 sample=0.0001 negative=3 window=10\n",
      "2017-06-15 12:58:30,101 : INFO : PROGRESS: at 3.75% examples, 387579 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:31,113 : INFO : PROGRESS: at 7.77% examples, 393280 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:32,117 : INFO : PROGRESS: at 11.96% examples, 404445 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:33,152 : INFO : PROGRESS: at 16.13% examples, 407017 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:34,164 : INFO : PROGRESS: at 20.23% examples, 408574 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:35,179 : INFO : PROGRESS: at 24.19% examples, 408368 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:36,216 : INFO : PROGRESS: at 28.43% examples, 409111 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:37,236 : INFO : PROGRESS: at 32.61% examples, 410557 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:38,247 : INFO : PROGRESS: at 36.76% examples, 411956 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:39,254 : INFO : PROGRESS: at 40.78% examples, 411812 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:40,255 : INFO : PROGRESS: at 44.73% examples, 411092 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:41,293 : INFO : PROGRESS: at 49.01% examples, 411935 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:42,370 : INFO : PROGRESS: at 53.24% examples, 411493 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:43,371 : INFO : PROGRESS: at 57.42% examples, 412646 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:44,389 : INFO : PROGRESS: at 61.44% examples, 412218 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:45,399 : INFO : PROGRESS: at 65.63% examples, 412952 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:46,414 : INFO : PROGRESS: at 69.71% examples, 412528 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:47,439 : INFO : PROGRESS: at 73.82% examples, 412870 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:48,467 : INFO : PROGRESS: at 78.01% examples, 413051 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:49,475 : INFO : PROGRESS: at 82.09% examples, 413294 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:50,491 : INFO : PROGRESS: at 86.20% examples, 413323 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:51,494 : INFO : PROGRESS: at 90.25% examples, 413211 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:52,505 : INFO : PROGRESS: at 94.24% examples, 412953 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:53,514 : INFO : PROGRESS: at 98.34% examples, 413091 words/s, in_qsize 15, out_qsize 0\n",
      "2017-06-15 12:58:53,796 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-06-15 12:58:53,801 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-06-15 12:58:53,821 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-06-15 12:58:53,824 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-06-15 12:58:53,825 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-06-15 12:58:53,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-15 12:58:53,841 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-15 12:58:53,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-15 12:58:53,861 : INFO : training on 11971245 raw words (10261902 effective words) took 24.8s, 414144 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10261902"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Doc2Vec(dm=0, dbow_words=1, min_count=4, negative=3,\n",
    "                hs=0, sample=1e-4, window=10, size=100, workers=8)\n",
    "\n",
    "model.build_vocab(DOCS)\n",
    "model.train(DOCS, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-15 12:58:59,409 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hailed_as', 0.7197465896606445),\n",
      " ('heroic', 0.6965265870094299),\n",
      " ('heroism', 0.6770747303962708),\n",
      " ('weary', 0.6507082581520081),\n",
      " ('honored', 0.6473628282546997),\n",
      " ('heroes', 0.6452208161354065),\n",
      " ('accomplished', 0.638401985168457),\n",
      " ('pyrrhic', 0.6361966133117676),\n",
      " ('kebbell', 0.6338528990745544),\n",
      " ('inspired_by', 0.632212221622467)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to query word\n",
    "pprint(model.most_similar('hero'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-15 12:59:06,873 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('simon_birch_1998', 0.6298867464065552),\n",
      " ('blues_brothers_2000_1998', 0.6213065385818481),\n",
      " ('great_dictator_the_1940', 0.6204599738121033),\n",
      " ('moon_over_parador_1988', 0.6066589951515198),\n",
      " ('six_string_samurai_1998', 0.6056036949157715),\n",
      " ('dragon_the_bruce_lee_story_1993', 0.6035102009773254),\n",
      " ('lenny_1974', 0.6014411449432373),\n",
      " ('condemned_the_2007', 0.5961964130401611),\n",
      " ('fallen_idol_the_1948', 0.5941512584686279),\n",
      " ('honeysuckle_rose_a_k_a_on_the_road_again_1980', 0.5934443473815918)]\n"
     ]
    }
   ],
   "source": [
    "# Find movies similar to query word\n",
    "vec = model['hero']\n",
    "pprint(model.docvecs.most_similar([vec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ -2.01952770e-01,  -4.74567771e-01,   4.21493530e-01,\n",
      "         3.94441038e-01,   2.12652594e-01,   2.74790764e-01,\n",
      "         4.28851217e-01,  -3.43415499e-01,  -3.13537687e-01,\n",
      "        -5.66040091e-02,  -2.06435144e-01,   6.66458681e-02,\n",
      "        -2.82495886e-01,  -2.58645266e-01,   2.34836519e-01,\n",
      "         4.22616273e-01,  -5.69512069e-01,   4.48908433e-02,\n",
      "        -1.36964023e-01,  -5.07732511e-01,  -2.62371629e-01,\n",
      "         1.52882054e-01,   3.52895856e-01,   6.34373307e-01,\n",
      "        -3.48489642e-01,  -1.74726322e-01,  -8.72953415e-01,\n",
      "        -5.49116075e-01,  -4.06443834e-01,   4.58787344e-02,\n",
      "        -3.79901975e-01,   7.24184588e-02,   1.34766370e-01,\n",
      "        -1.24760069e-01,  -4.88436133e-01,  -3.21606070e-01,\n",
      "         3.28891248e-01,   1.24825358e+00,   8.26135933e-01,\n",
      "        -3.37436527e-01,   1.12053268e-01,   1.40768752e-01,\n",
      "        -5.69933832e-01,   2.52969474e-01,  -5.93420267e-02,\n",
      "        -4.86876726e-01,  -4.36180830e-02,   3.61817747e-01,\n",
      "         2.46026829e-01,   2.19440535e-01,  -4.30904835e-01,\n",
      "        -2.88652547e-04,  -3.14016402e-01,   1.39419913e-01,\n",
      "         1.12717241e-01,  -2.59655744e-01,   4.00348037e-01,\n",
      "         1.48292691e-01,   2.26322487e-02,  -3.45300078e-01,\n",
      "        -1.78459510e-01,   2.59070396e-01,   3.96800578e-01,\n",
      "         3.34289640e-01,   3.65118951e-01,   3.67022306e-01,\n",
      "         4.73183423e-01,   2.58978933e-01,   5.36982358e-01,\n",
      "        -5.40039897e-01,  -1.44893229e-01,  -3.50266583e-02,\n",
      "        -5.25881685e-02,   5.09174228e-01,   1.26205325e-01,\n",
      "        -1.61453769e-01,   4.72687706e-02,  -2.63843358e-01,\n",
      "         8.13044384e-02,  -5.67070656e-02,   2.58130342e-01,\n",
      "        -2.10283566e-02,   4.13876534e-01,  -3.81745608e-03,\n",
      "         2.32700989e-01,  -2.08002180e-01,   7.32575729e-02,\n",
      "         2.87321299e-01,   4.66929793e-01,  -3.22053105e-01,\n",
      "        -3.38069201e-01,  -4.63976443e-01,  -1.04734927e-01,\n",
      "        -3.70651931e-01,  -1.84299629e-02,   1.40605390e-01,\n",
      "        -4.86802310e-04,   2.52095193e-01,  -5.03767014e-01,\n",
      "         2.80247271e-01], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint(model.docvecs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Glory (1989)\n",
      "[('cross_of_iron_1977', 0.8848959803581238),\n",
      " ('last_samurai_the_2003', 0.8841438293457031),\n",
      " ('lawrence_of_arabia_1962', 0.8840969204902649),\n",
      " ('sergeant_york_1941', 0.8820092678070068),\n",
      " ('rio_grande_1950', 0.8784996271133423),\n",
      " ('we_were_soldiers_2002', 0.876758337020874),\n",
      " ('patton_1970', 0.8763837814331055),\n",
      " ('they_were_expendable_1945', 0.8700815439224243),\n",
      " ('enemy_at_the_gates_2001', 0.8669483661651611),\n",
      " ('patriot_the_2000', 0.866405725479126)]\n",
      "\n",
      "Query: Boogie Nights (1997)\n",
      "[('frogs_for_snakes_1998', 0.8685746192932129),\n",
      " ('car_wash_1976', 0.8356642723083496),\n",
      " ('empire_2002', 0.8300975561141968),\n",
      " ('broken_hearts_club_the_2000', 0.8214051723480225),\n",
      " ('keys_to_tulsa_1997', 0.8202093243598938),\n",
      " ('bobby_2006', 0.8180745244026184),\n",
      " ('owning_mahowny_2003', 0.8179845809936523),\n",
      " ('smile_1975', 0.8169777393341064),\n",
      " ('middle_men_2009', 0.8127021789550781),\n",
      " ('hearts_of_the_west_1975', 0.8116779327392578)]\n",
      "\n",
      "Query: You've Got Mail (1998)\n",
      "[('this_is_my_life_1992', 0.8781754970550537),\n",
      " ('far_from_heaven_2002', 0.8719257116317749),\n",
      " ('love_walked_in_1998', 0.8705319166183472),\n",
      " ('broken_flowers_2005', 0.8701742887496948),\n",
      " ('high_fidelity_2000', 0.8693627119064331),\n",
      " ('caught_1996', 0.8654224276542664),\n",
      " ('art_school_confidential_2006', 0.8642385005950928),\n",
      " ('merry_war_a_1997', 0.8609732389450073),\n",
      " ('guinevere_1999', 0.8599427938461304),\n",
      " ('wonder_boys_2000', 0.8596983551979065)]\n",
      "\n",
      "Query: I, Robot (2004)\n",
      "[('aeon_flux_2005', 0.8923779726028442),\n",
      " ('babylon_5_thirdspace_1998', 0.8733217716217041),\n",
      " ('judge_dredd_1995', 0.8715108633041382),\n",
      " ('ghost_in_the_shell_2_innocence_a_k_a_innocence_inosensu_2004',\n",
      "  0.871153712272644),\n",
      " ('appleseed_appurushîdo_2004', 0.868729293346405),\n",
      " ('impostor_2002', 0.8675097227096558),\n",
      " ('ghost_in_the_shell_2_0_2008', 0.8673632144927979),\n",
      " ('black_mask_hak_hap_1996', 0.8642467260360718),\n",
      " ('watchmen_tales_of_the_black_freighter_2009', 0.8627099394798279),\n",
      " ('ghost_in_the_shell_kôkaku_kidôtai_1995', 0.8622543811798096)]\n",
      "\n",
      "Query: Walk the Line (2005)\n",
      "[('glitter_2001', 0.9031431674957275),\n",
      " ('new_york_new_york_1977', 0.8995782732963562),\n",
      " ('crazy_heart_2009', 0.8914583921432495),\n",
      " ('once_2006', 0.8881127238273621),\n",
      " ('american_pop_1981', 0.8853437900543213),\n",
      " ('rose_the_1979', 0.8820393681526184),\n",
      " ('sing_street_2016', 0.8771891593933105),\n",
      " ('mambo_kings_the_1992', 0.8719747066497803),\n",
      " ('connie_and_carla_2004', 0.8705425262451172),\n",
      " ('coyote_ugly_2000', 0.8688702583312988)]\n",
      "\n",
      "Query: Black Hawk Down (2001)\n",
      "[('lone_survivor_2013', 0.9508054852485657),\n",
      " ('behind_enemy_lines_2001', 0.9431121349334717),\n",
      " ('braddock_missing_in_action_iii_1988', 0.9379656314849854),\n",
      " ('fighting_seabees_the_1944', 0.9357259273529053),\n",
      " ('rambo_iii_1988', 0.9349703788757324),\n",
      " ('battle_los_angeles_2011', 0.9348721504211426),\n",
      " ('rambo_first_blood_part_ii_1985', 0.929368257522583),\n",
      " ('firefox_1982', 0.9271040558815002),\n",
      " ('operation_dumbo_drop_1995', 0.9262722730636597),\n",
      " ('aces_iron_eagle_iii_1992', 0.925025999546051)]\n",
      "\n",
      "Query: 300 (2007)\n",
      "[('300_rise_of_an_empire_2014', 0.9598897695541382),\n",
      " ('meet_the_spartans_2008', 0.9497368931770325),\n",
      " ('mulan_1998', 0.9416007399559021),\n",
      " ('hercules_2014', 0.9377769231796265),\n",
      " ('asterix_obelix_vs_caesar_astérix_et_obélix_contre_césar_1999',\n",
      "  0.936866819858551),\n",
      " ('kagemusha_1980', 0.9364078044891357),\n",
      " ('musa_the_warrior_musa_2001', 0.9187799096107483),\n",
      " ('last_samurai_the_2003', 0.9124765396118164),\n",
      " ('samurai_ii_duel_at_ichijoji_temple_zoku_miyamoto_musashi_ichijôji_no_kettô_1955',\n",
      "  0.9096969962120056),\n",
      " ('gladiator_2000', 0.9087709784507751)]\n",
      "\n",
      "Query: Superbad (2007)\n",
      "[('why_stop_now_2012', 0.8543262481689453),\n",
      " ('kids_1995', 0.8521965742111206),\n",
      " ('touchy_feely_2013', 0.8404510021209717),\n",
      " ('laggies_2014', 0.8401209115982056),\n",
      " ('hall_pass_2011', 0.8369299173355103),\n",
      " ('overnight_delivery_1998', 0.8346924781799316),\n",
      " ('uncle_buck_1989', 0.832791268825531),\n",
      " ('swimfan_2002', 0.831469714641571),\n",
      " ('blackrock_1997', 0.8314402103424072),\n",
      " ('thirteen_2003', 0.8304851055145264)]\n",
      "\n",
      "Query: Cars 3 (2017)\n",
      "[('bite_the_bullet_1975', 0.9230390191078186),\n",
      " ('facing_the_giants_2006', 0.9065691232681274),\n",
      " ('reversal_of_fortune_1990', 0.9049080610275269),\n",
      " ('pain_gain_2013', 0.8991965055465698),\n",
      " ('world_s_fastest_indian_the_2005', 0.8913697600364685),\n",
      " ('american_flyers_1985', 0.8903622627258301),\n",
      " ('days_of_thunder_1990', 0.8861037492752075),\n",
      " ('everyone_s_hero_2006', 0.8858989477157593),\n",
      " ('august_rush_2007', 0.8809073567390442),\n",
      " ('mystery_alaska_1999', 0.8789489269256592)]\n"
     ]
    }
   ],
   "source": [
    "# Find movies similar to a query movie\n",
    "#for title in df.title.tolist()[:1]:\n",
    "targetMovie = ['Glory (1989)', 'Boogie Nights (1997)', 'You\\'ve Got Mail (1998)', \\\n",
    "               'I, Robot (2004)', 'Walk the Line (2005)', 'Black Hawk Down (2001)', \\\n",
    "               '300 (2007)', 'Superbad (2007)', 'Cars 3 (2017)']\n",
    "#for title in name_list[790:791]:\n",
    "for title in targetMovie:\n",
    "    print(\"\\nQuery: %s\"%title)\n",
    "    doctag = '_'.join(preprocess(title))\n",
    "    pprint(model.docvecs.most_similar(doctag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Glory (1989)\n",
      "[('54th', 0.9147264361381531),\n",
      " ('regimental', 0.9103386998176575),\n",
      " ('eastern_front', 0.9068944454193115),\n",
      " ('stransky', 0.9046857357025146),\n",
      " ('battalion', 0.9004204273223877),\n",
      " ('zulu', 0.8941487669944763),\n",
      " ('regiment', 0.8896756768226624),\n",
      " ('wehrmacht', 0.8896723389625549),\n",
      " ('north_africa', 0.8894959092140198),\n",
      " ('jin_tae', 0.8863554000854492)]\n",
      "\n",
      "Query: Boogie Nights (1997)\n",
      "[('matt_dillon', 0.8894107937812805),\n",
      " ('robb', 0.8807612657546997),\n",
      " ('hustler', 0.877149760723114),\n",
      " ('shea', 0.874844491481781),\n",
      " ('snorting', 0.8693946003913879),\n",
      " ('southern_california', 0.8691381812095642),\n",
      " ('showgirl', 0.8676514625549316),\n",
      " ('anthony_lapaglia', 0.8666927814483643),\n",
      " ('clifton', 0.8661743402481079),\n",
      " ('wannabe', 0.8611297607421875)]\n",
      "\n",
      "Query: You've Got Mail (1998)\n",
      "[('malin', 0.9109910726547241),\n",
      " ('greeting_card', 0.893404483795166),\n",
      " ('stylish', 0.8887248635292053),\n",
      " ('fancies', 0.8846456408500671),\n",
      " ('record_store', 0.8842371106147766),\n",
      " ('melanie_griffith', 0.8837442398071289),\n",
      " ('hotels', 0.8831743001937866),\n",
      " ('one_afternoon', 0.8812041282653809),\n",
      " ('art_museum', 0.8792902231216431),\n",
      " ('åkerman', 0.8790268898010254)]\n",
      "\n",
      "Query: I, Robot (2004)\n",
      "[('spooner', 0.9612483978271484),\n",
      " ('lanning', 0.9455718994140625),\n",
      " ('ns_5', 0.9375016689300537),\n",
      " ('viki', 0.9126883745193481),\n",
      " ('usr', 0.902353048324585),\n",
      " ('theorizes_that', 0.9003243446350098),\n",
      " ('warfare', 0.894472599029541),\n",
      " ('bioroids', 0.892452597618103),\n",
      " ('togusa', 0.8903031349182129),\n",
      " ('super_soldier', 0.8897426128387451)]\n",
      "\n",
      "Query: Walk the Line (2005)\n",
      "[('beers', 0.8911832571029663),\n",
      " ('recording_studio', 0.8896524906158447),\n",
      " ('gigs', 0.8860188722610474),\n",
      " ('nightclubs', 0.8844675421714783),\n",
      " ('carnegie_hall', 0.8824201822280884),\n",
      " ('triplette', 0.8816620111465454),\n",
      " ('calvero', 0.8814980983734131),\n",
      " ('country_music', 0.8813920617103577),\n",
      " ('cherie', 0.8811478614807129),\n",
      " ('stardust', 0.8809089660644531)]\n",
      "\n",
      "Query: Black Hawk Down (2001)\n",
      "[('super_six', 0.9691014289855957),\n",
      " ('an_airstrike', 0.9646178483963013),\n",
      " ('airspace', 0.9594252109527588),\n",
      " ('navy_seals', 0.9581761360168457),\n",
      " ('patrols', 0.9537911415100098),\n",
      " ('messerschmitt', 0.9534157514572144),\n",
      " ('anti_aircraft', 0.9519707560539246),\n",
      " ('delta_force', 0.9503589272499084),\n",
      " ('aidid', 0.9497663974761963),\n",
      " ('usaf', 0.9495841264724731)]\n",
      "\n",
      "Query: 300 (2007)\n",
      "[('spartans', 0.9819858074188232),\n",
      " ('xerxes', 0.9805100560188293),\n",
      " ('shan_yu', 0.9626002311706543),\n",
      " ('ephialtes', 0.9616128206253052),\n",
      " ('kagemusha', 0.9597006440162659),\n",
      " ('rhesus', 0.9594496488571167),\n",
      " ('leonidas', 0.9591337442398071),\n",
      " ('persians', 0.9537163972854614),\n",
      " ('themistocles', 0.9513292908668518),\n",
      " ('gorgo', 0.9512251019477844)]\n",
      "\n",
      "Query: Superbad (2007)\n",
      "[('fogell', 0.9710012674331665),\n",
      " ('wild_party', 0.8832083940505981),\n",
      " ('fake_id', 0.8807768821716309),\n",
      " ('condom', 0.8765711784362793),\n",
      " ('damone', 0.876042902469635),\n",
      " ('overdoses_on', 0.8756676316261292),\n",
      " ('things_go', 0.87189781665802),\n",
      " ('ejaculates', 0.871166467666626),\n",
      " ('bump_into', 0.8625075817108154),\n",
      " ('changing_room', 0.8608549237251282)]\n",
      "\n",
      "Query: Cars 3 (2017)\n",
      "[('lightning_mcqueen', 0.9634252786636353),\n",
      " ('hurdles', 0.9561236500740051),\n",
      " ('regazzoni', 0.9519268274307251),\n",
      " ('talladega', 0.949691891670227),\n",
      " ('whichever', 0.9390273690223694),\n",
      " ('hesketh', 0.9362757205963135),\n",
      " ('taejo', 0.9350268840789795),\n",
      " ('qualifying', 0.9314831495285034),\n",
      " ('ballpark', 0.9310935735702515),\n",
      " ('nascar', 0.9286566972732544)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to a query movie\n",
    "targetMovie = ['Glory (1989)', 'Boogie Nights (1997)', 'You\\'ve Got Mail (1998)', \\\n",
    "               'I, Robot (2004)', 'Walk the Line (2005)', 'Black Hawk Down (2001)', \\\n",
    "               '300 (2007)', 'Superbad (2007)', 'Cars 3 (2017)']\n",
    "#for title in name_list[790:791]:\n",
    "for title in targetMovie:\n",
    "    print(\"\\nQuery: %s\"%title)\n",
    "    doctag = '_'.join(preprocess(title))\n",
    "    vec = model.docvecs[doctag]\n",
    "    pprint(model.most_similar([vec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tsne'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-2fa29a0d283c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtsne\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbh_sne\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpca_transform_vecs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tsne'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from tsne import bh_sne\n",
    "\n",
    "def pca_transform_vecs(vecs, n=50):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(vecs)\n",
    "    return pca.transform(vecs)\n",
    "\n",
    "def tsne_plot(titles, dims=40, perplexity=6, save_as=''):\n",
    "    doctags = ['_'.join(preprocess(title)) for title in titles]\n",
    "    vecs = np.array([unitvec(model.docvecs[doctag]) for doctag in doctags])    \n",
    "    # First doing pca on the vectors can reduce the noise and yield a better\n",
    "    # 2d projection\n",
    "    small_vecs = pca_transform_vecs(vecs, dims)\n",
    "    tsne_vecs = bh_sne(small_vecs, perplexity=perplexity)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18, 18))\n",
    "    ax.scatter(tsne_vecs[:,0], tsne_vecs[:,1])\n",
    "\n",
    "    # Annotate points with the movie title\n",
    "    for i, title in enumerate(titles):\n",
    "        ax.annotate(title, \n",
    "                    xy=(tsne_vecs[i,0],tsne_vecs[i,1]), \n",
    "                    fontsize=12, alpha=.9)\n",
    "\n",
    "    plt.xlim(min(tsne_vecs[:,0])-0.3, max(tsne_vecs[:,0])+0.3) \n",
    "    plt.ylim(min(tsne_vecs[:,1])-0.3, max(tsne_vecs[:,1])+0.3)\n",
    "    if save_as:\n",
    "        fig.savefig(save_as, dpi=fig.dpi)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "TOP_N = 90\n",
    "query = 'type==\"series\" and rating>7.0'\n",
    "titles = df.query(query).title.tolist()[:TOP_N]\n",
    "fig = tsne_plot(titles, save_as='tv_shows.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = 'type==\"movie\" and rating>7.0'\n",
    "titles = df.query(query).title.tolist()[:TOP_N]\n",
    "fig = tsne_plot(titles, save_as='movies.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
